{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_chromagram(waveform, sample_rate):\n",
    "    # STFT computed here explicitly\n",
    "    stft_spectrogram = np.abs(librosa.stft(waveform))\n",
    "    # Produce the chromagram for all STFT frames\n",
    "    chromagram = librosa.feature.chroma_stft(S = stft_spectrogram, sr = sample_rate, n_chroma = 128).T\n",
    "    chromagram = MinMaxScaler((-255, 255)).fit_transform(chromagram)\n",
    "    return chromagram\n",
    "\n",
    "def feature_melspectrogram(waveform, sample_rate):\n",
    "    # Produce the mel spectrogram for all STFT frames\n",
    "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
    "    melspectrogram = librosa.feature.melspectrogram(y = waveform, sr = sample_rate, n_mels = 128, fmax = 8000).T\n",
    "    melspectrogram = MinMaxScaler((-255, 255)).fit_transform(melspectrogram)\n",
    "    return melspectrogram\n",
    "\n",
    "def feature_mfcc(waveform, sample_rate):\n",
    "    # Compute the MFCCs for all STFT frames\n",
    "    # 128 filterbanks = 128 coefficients\n",
    "    mfc_coefficients = librosa.feature.mfcc(y = waveform, sr = sample_rate, n_mfcc = 128).T\n",
    "    mfc_coefficients = MinMaxScaler((-255, 255)).fit_transform(mfc_coefficients)\n",
    "    return mfc_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file):\n",
    "    # load an individual soundfile\n",
    "    with soundfile.SoundFile(file) as audio:\n",
    "        waveform = audio.read(dtype=\"float32\")\n",
    "\n",
    "        # get the first channel of the audio only\n",
    "        if len(waveform.shape) != 1:\n",
    "            waveform = waveform[:441000, 0]\n",
    "        else:\n",
    "            waveform = waveform[:441000]\n",
    "        sample_rate = audio.samplerate\n",
    "\n",
    "        # compute features of soundfile\n",
    "        melspectrogram = feature_melspectrogram(waveform, sample_rate)\n",
    "        mfc_coefficients = feature_mfcc(waveform, sample_rate)\n",
    "        chromagram = feature_chromagram(waveform, sample_rate)\n",
    "        \n",
    "        # use np.dstack to stack our feature arrays depth wise to create a feature matrix\n",
    "        feature_matrix = np.dstack((chromagram, melspectrogram, mfc_coefficients))\n",
    "        # print(feature_matrix.shape)\n",
    "\n",
    "        return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862, 128, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = get_features('../audio/Hum/Frozen_hum/5806.wav')\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(file_list, label_list):\n",
    "  arr = []\n",
    "  label = []\n",
    "  cnt = 0\n",
    "  for file, l in zip(file_list, label_list):\n",
    "    if cnt%300 == 0: print(cnt)\n",
    "    cnt += 1\n",
    "    try:\n",
    "      f = get_features(file)\n",
    "      if f.shape == (862, 128, 3):\n",
    "        arr.append(get_features(file))\n",
    "        label.append(l)\n",
    "    except:\n",
    "      print(file)\n",
    "  return np.array(arr), np.array(label)\n",
    "\n",
    "def alex(num_labels, input_shape):\n",
    "    alexNet = tf.keras.models.Sequential([\n",
    "    # input layer\n",
    "      layers.InputLayer(input_shape),\n",
    "    # 1st layer\n",
    "      layers.Conv2D(filters = 64, kernel_size = (11, 11), strides = (4, 4), name = 'layer1_conv2d_11_4'),\n",
    "      layers.BatchNormalization(name = 'layer1_normalize'),\n",
    "      layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), name = 'layer1_maxpool'),\n",
    "      layers.Activation('relu', name = 'layer1_relu'),\n",
    "    # 2nd layer\n",
    "      layers.Conv2D(filters = 128, kernel_size = (5, 5), strides = (1, 1), padding = 'same', name = 'layer2_conv2d_5_1'),\n",
    "      layers.BatchNormalization(name = 'layer2_normalize'),\n",
    "      layers.MaxPool2D(pool_size = (2, 2), strides = (1, 1), name = 'layer2_maxpool'),\n",
    "      layers.Activation('relu', name = 'layer2_relu'),\n",
    "    # 3rd layer\n",
    "      layers.Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', name = 'layer1_conv2d_3_1'),\n",
    "      layers.BatchNormalization(name = 'layer3_normalize'),\n",
    "      layers.MaxPool2D(pool_size = (2, 2), strides = (1, 1), name = 'layer3_maxpool'),\n",
    "      layers.Activation('relu', name = 'layer3_relu'),\n",
    "    # transition layer\n",
    "      layers.Flatten(name = 'FC_layer'),\n",
    "    # 1st Dense layer\n",
    "      layers.Dense(1000, activation='relu', name = 'Dense_100'),\n",
    "    # 2nd Dense layer\n",
    "      layers.Dense(200, activation='relu', name = 'Dense_20'),\n",
    "    # # Output layer\n",
    "      layers.Dense(num_labels, activation = 'softmax', name = 'Output')\n",
    "    ])\n",
    "    alexNet.compile(optimizer=\"Adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    # alexNet.summary()\n",
    "    return alexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_dir(dir):\n",
    "    dir_list = [l[0] for l in os.walk(dir)][1:]\n",
    "    print(dir_list)\n",
    "\n",
    "    arr = []\n",
    "\n",
    "    for i, song_dir in enumerate(dir_list):\n",
    "        song_file = [file for file in os.listdir(song_dir) if 'wav' in file]\n",
    "        data = pd.DataFrame({'file': song_file, 'label': i})\n",
    "        data['file'] = data['file'].apply(lambda file: f'{song_dir}/{file}')\n",
    "        arr.append(data)\n",
    "\n",
    "    arr = pd.concat(arr, axis=0)\n",
    "    \n",
    "    dataset = arr['file']\n",
    "\n",
    "    label = pd.get_dummies(arr['label'], columns=['label'])\n",
    "\n",
    "    return dataset, label.to_numpy()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./audio/Hum/Frozen_hum', './audio/Hum/Hakuna_hum', './audio/Hum/Mamma_hum', './audio/Hum/Panther_hum', './audio/Hum/Potter_hum', './audio/Hum/Rain_hum', './audio/Hum/Showman_hum', './audio/Hum/StarWars_hum']\n"
     ]
    }
   ],
   "source": [
    "dataset, label = get_data_from_dir('../audio/Hum/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3367,)\n",
      "(3367, 8)\n",
      "(1443,)\n",
      "(1443, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.3, stratify = label, random_state = 4444)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "./audio/Hum/Mamma_hum/4981.wav\n"
     ]
    }
   ],
   "source": [
    "X_trans, y_trans = transformer(X_train.to_numpy(), y_train)\n",
    "\n",
    "with open('./data/train_8.npz', 'wb') as train_file:\n",
    "    np.savez(train_file, x = X_trans, y = y_trans)\n",
    "\n",
    "X_test_trans, y_test_trans = transformer(X_test.to_numpy(), y_test)\n",
    "\n",
    "with open('./data/test_8.npz', 'wb') as test_file:\n",
    "    np.savez(test_file, x = X_test_trans, y = y_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = get_features('../audio/Hum/Frozen_hum/5798.wav')\n",
    "alex_model = alex(y_train.shape[-1], wave.shape)\n",
    "\n",
    "alex_model.fit(X_trans, y_trans, epochs = 50, validation_split = 0.2, use_multiprocessing = True)\n",
    "\n",
    "alex_model.save('./alex_record/alex_8')\n",
    "\n",
    "print(alex_model.evaluate(X_test_trans, y_test_trans))\n",
    "\n",
    "# acc 84.15% test 99.96% train 8 label normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncode(y_tmp):\n",
    "    y_tmp = np.argmax(y_tmp, axis = 1)\n",
    "\n",
    "    y_tmp = pd.get_dummies(y_tmp).to_numpy()\n",
    "\n",
    "    return y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_loaded = None\n",
    "y_train_loaded = None\n",
    "X_test_loaded = None\n",
    "y_test_loaded = None\n",
    "\n",
    "with open('./data/train_8.npz', 'rb') as train_file:\n",
    "    train = np.load(train_file)\n",
    "    X_train_loaded = train['x']\n",
    "    y_train_loaded = train['y']\n",
    "\n",
    "with open('./data/test_8.npz', 'rb') as test_file:\n",
    "    test = np.load(test_file)\n",
    "    X_test_loaded = test['x']\n",
    "    y_test_loaded = test['y']\n",
    "\n",
    "song_train = pd.DataFrame(np.argmax(y_train_loaded, axis=1))\n",
    "song_test = pd.DataFrame(np.argmax(y_test_loaded, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2_loc = np.where(song_train[0].apply(lambda x: x in [0, 1]))[0]\n",
    "test_2_loc = np.where(song_test[0].apply(lambda x: x in [0, 1]))[0]\n",
    "\n",
    "song_2_X_train = X_train_loaded[train_2_loc]\n",
    "song_2_y_train = y_train_loaded[train_2_loc]\n",
    "song_2_X_test = X_test_loaded[test_2_loc]\n",
    "song_2_y_test = y_test_loaded[test_2_loc]\n",
    "\n",
    "with open('./data/train_2.npz', 'wb') as train_file:\n",
    "    np.savez(train_file, x = song_2_X_train, y = song_2_y_train)\n",
    "\n",
    "with open('./data/test_2.npz', 'wb') as test_file:\n",
    "    np.savez(test_file, x = song_2_X_test, y = song_2_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3_loc = np.where(song_train[0].apply(lambda x: x in [0, 1, 4]))[0]\n",
    "test_3_loc = np.where(song_test[0].apply(lambda x: x in [0, 1, 4]))[0]\n",
    "\n",
    "song_3_X_train = X_train_loaded[train_3_loc]\n",
    "song_3_y_train = y_train_loaded[train_3_loc]\n",
    "song_3_X_test = X_test_loaded[test_3_loc]\n",
    "song_3_y_test = y_test_loaded[test_3_loc]\n",
    "\n",
    "with open('./data/train_3.npz', 'wb') as train_file:\n",
    "    np.savez(train_file, x = song_3_X_train, y = song_3_y_train)\n",
    "\n",
    "with open('./data/test_3.npz', 'wb') as test_file:\n",
    "    np.savez(test_file, x = song_3_X_test, y = song_3_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_5_loc = np.where(song_train[0].apply(lambda x: x [0, 1, 3, 4, 7]))[0]\n",
    "test_5_loc = np.where(song_test[0].apply(lambda x: x [0, 1, 3, 4, 7]))[0]\n",
    "\n",
    "song_5_X_train = X_train_loaded[train_5_loc]\n",
    "song_5_y_train = y_train_loaded[train_5_loc]\n",
    "song_5_X_test = X_test_loaded[test_5_loc]\n",
    "song_5_y_test = y_test_loaded[test_5_loc]\n",
    "\n",
    "with open('./data/train_5.npz', 'wb') as train_file:\n",
    "    np.savez(train_file, x = song_5_X_train, y = song_5_y_train)\n",
    "\n",
    "with open('./data/test_5.npz', 'wb') as test_file:\n",
    "    np.savez(test_file, x = song_5_X_test, y = song_5_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = get_features('../audio/Hum/Frozen_hum/5798.wav')\n",
    "for i in [2, 3, 5, 8]:\n",
    "\n",
    "    alex_model = alex(i, wave.shape)\n",
    "\n",
    "    with open(f'./data/train_{i}.npz', 'rb') as train_file:\n",
    "        train = np.load(train_file)\n",
    "\n",
    "        X_train = train['x']\n",
    "        y_train = train['y']\n",
    "        y_train = labelEncode(y_train)\n",
    "\n",
    "        alex_model.fit(X_train, y_train, epochs = 50, validation_split = 0.2, use_multiprocessing = True)\n",
    "\n",
    "        alex_model.save(f'./alex_record/alex_{i}')\n",
    "\n",
    "    with open(f'./data/test_{i}.npz', 'rb') as test_file:\n",
    "        test = np.load(test_file)\n",
    "\n",
    "        X_test = test['x']\n",
    "        y_test = test['y']\n",
    "        y_test = pd.get_dummies(np.argmax(y_test, axis = 1)).to_numpy()\n",
    "\n",
    "        print(alex_model.evaluate(X_test, y_test))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
